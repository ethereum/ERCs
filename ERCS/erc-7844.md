---
eip: 7844
title: Consolidated Dynamic Storage (CDS)
description: Unbounded in-place storage structure upgradeability managed at the contract level.
author: Cameron Warnick (@wisecameron)
discussions-to: https://ethereum-magicians.org/t/erc-7844-consolidated-dynamic-storage-cds/22217
status: Draft
type: Standards Track
category: ERC
created: 2024-12-13
---

## Abstract  

**Consolidated Dynamic Storage (CDS)** introduces a dedicated storage contract that provides dynamically extendable, hash-indexed storage spaces shared across multiple contracts. By consolidating structured storage into a single, logically segmented layer, CDS eliminates slot conflicts, enables deterministic schema expansion, and enforces strict separation between storage and execution.  Consolidated multi-contract storage management is also offered by the Diamond Pattern.  CDS expands on this concept by introducing consistent cross-contract access and modification procedures, allowing cross-contract dependencies to leverage standardized interfaces that remain stable regardless of logical or data structure updates.  

CDS enables in-place storage structure extension, introducing mapped storage spaces populated by "extendible structs," and thereby removing any need for storage-driven contract redeployments or manual slot management.  Storage spaces can be dynamically allocated in-place, and are logically segmented using an efficient hashing algorithm.  By leveraging basic access controls, development teams can ensure secure storage management for an arbitrary-length collection of linked contracts with varying permissions, gaining the resilience of siloed storage within a unified storage context.  This holistic approach to deterministic storage management facilitates safe upgrades while reducing operational costs and complexity. With on-chain storage considerations managed by a deterministic protocol, developers are free to focus solely on contract logic, enabling streamlined development while reducing the odds of vulnerabilities reaching production.

Additionally, CDS optimizes execution efficiency by enforcing a single-hop storage access model, replacing deep delegation chains with direct, permissioned storage interactions. This reduces redundant SLOAD operations and lowers gas overhead in multi-contract systems. These properties make CDS particularly well-suited for DeFi protocols, DAOs, and modular architectures requiring long-term upgradeability without increasing complexity or risk.

## Motivation  

![Scaling CDS](../assets/erc-7844/ScalingCDS.svg)

The Ethereum ecosystem relies on upgradeable smart contract patterns to enable flexibility in evolving protocols and systems. Contemporary solutions such as **Proxy-Delegate** and [ERC-2535](./eip-2535.md)'s **Diamond Standard** enable contract swaps, but do not take a holistic approach to 


1. **Fractured Cross-Contract Links** 
	Adding new fields to existing *struct* types can cause a variety of complications in the domain of cross-contract interoperability.  

	*Function Selector Changes:* If a function takes *struct* as a parameter, changes to the struct layout will change its function selector.  External to the now-deprecated selector will route to the fallback function (or simply fail) until those contracts are re-deployed.  Coordinating re-deployments for all dependent contracts can be challenging, especially in cross-organizational settings.

	*Broken Return Data Encoding:* If a function returns a struct, even if it’s not passed as an argument, changes to its structure invalidate the expected return data encoding.  Any function expecting the old layout will receive extra bytes, causing the ABI decoder to revert the transaction.

	*Calldata Decoding Failures:* Struct modifications also affect how externally supplied calldata is parsed. Functions that rely on ABI encoding to decode struct parameters will break if the expected data structure changes, leading to silent failures or unexpected execution paths. This is particularly problematic for modular contract ecosystems, where various contracts interact via cross-contract calls and must interpret the same struct definitions consistently.

2.	**Compulsory Redeployments** 
	Updating storage structures is not universally supported. Even when Proxy-Delegate architectures are used, storage modifications almost always require contract redeployments. Expanding storage structures without altering contract bytecode is possible in theory but impractical in most real-world scenarios—any functional change, such as new getters or modified logic, necessitates redeployment.

	This imposes direct costs in both gas and operational complexity. Additionally, modifying existing contract logic can raise security concerns among users who rely on the protocol’s integrity. For protocols governed by decentralized mechanisms, complexities including coordinating upgrades across disparate governance layers can introduce further friction, making even minor storage modifications a potentially time-consuming and costly process.

3.	**Lack of Standardization in Access Routines** 
	No two protocols handle storage in exactly the same way: each introduces unique struct layouts, slot assignments, and upgrade management strategies. As a result, integrating with external contracts requires adapting to different storage access models.

	Unlike standardized token interfaces, storage lacks a universal querying system. Contracts frequently rely on inefficient or delicate solutions including:

	* Hard-coded storage slot references, which introduce fragility when upgrades modify slot positions.
	* Mirrored state variables, which duplicate data inefficiently, increasing gas costs.
	* Custom getter/setter functions, which increase deployment costs while requiring integrators to implement protocol-specific logic to retrieve state.  

	More fundamentally, access patterns may be subject to change—an integration built for one contract version may break when the underlying storage structure is updated, requiring maintenance across multiple versions.

4. **Manual Storage Management** 
	Storage updates are inherently high-risk due to Solidity’s strict alignment rules. Even when following best practices, upgradeable storage models require careful management to avoid introducing permanent corruption.

	While Proxy-Delegate and Diamond Storage architectures provide upgrade paths, they require explicit tracking of storage layouts. Misaligned struct modifications or incorrect slot allocations can cause irrecoverable state corruption.

	Additionally, the need for manual slot assignments and upgrade procedures introduces a security risk—any miscalculation in struct offsets, slot positions, or initialization routines can lead to unintended storage overwrites. While careful audits and best practices reduce this risk, they do not eliminate it entirely.

	It is true that best practices can largely mitigate the risks associated with storage updates. However, the potential for breaking changes remains a technical burden in itself—ensuring upgrade safety requires significant time, effort, and expertise, particularly in complex ecosystems.

5.  **Siloed Storage**
	On-chain storage is often tied to individual contracts rather than a unified data management layer.  This leads to complex linked structures and multi-hop access patterns, where operations require data aggregated from multiple external dependencies.  This added complexity and computational overhead is purely a burden, and can be avoided by leveraging dedicated storage layers with a cross-contract scope, as is often seen in the Diamond Pattern.  

6.  **Long-Term Technical Debt and Maintainability** 
	Factors including adapters, siloed storage, multi-hops, and dependent interfaces introduce new risks and considerations, increasing the complexity of upgrades as ecosystem scope expands.  The absence of these considerations streamlines the upgrade process considerably, allowing developers to prioritize optimizing and securing critical business logic.  Additionally, increased lines of code and complexity typically garner higher audit costs, while increasing the odds that vulnerable code makes it to production.


## Specification 

![Adaptability](../assets/erc-7844/Adaptability.svg)

The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY” and “OPTIONAL” in this document are to be interpreted as described in RFC 2119.

### Extendable Structs and Storage Spaces
- Extendable structs **MUST** leverage dynamic mappings with deterministic field hashes (`keccak256`).  
- The base struct and its additions **MUST** remain immutable, while fields **MUST** be dynamically appendable.
- Storage spaces **MUST** equate to a simple extension of the hashing structure, segmenting both struct-defining and active data.

Each struct member **MUST** be defined using the following compact metadata structures:

| **Field**  | **Bits** | **Description**                          |
| ---------- | -------- | ---------------------------------------- |
| `bitCount` | 128      | Starting bit offset for the member.      |
| `size`     | 64       | Size of the member in bits.              |
| `type`     | 64       | Type ID (e.g., `uint256`, `bool`, etc.). |

### Type IDs:

| **Type**                   | **ID** | **Size**     |
| -------------------------- | ------ | ------------ |
| `uint`                     | 1      | 8...256 bits |
| `int`                      | 2      | 8...256 bits |
| `bool`                     | 3      | 8 bits       |
| `address`                  | 4      | 160 bits     |
| `bytes32 (optional)`       | 5      | 256 bits     |
| `string (≡ bytes)`         | 6      | Dynamic      |

*For arrays, developers **MAY** define unpacking logic to treat `string` or `bytes` fields as indexed collections of dynamic elements.*

### Hash Structure:
There are three main segments that **MUST** include separate hashing structures to resolve any potential for collisions, meta-segmented by their particular storage spaces.  These are: storage space state data and member-specific data, storage space live data, and storage space dynamic data. 

There are two special values that **MUST** be included: a `safeIndex` and a `stringIndex`.  Both are expounded upon in detail below.

Developers **SHOULD** include a unique hash offset for each space, as this simplifies the development and audit process considerably, and thereby greatly reduces the risk of improper implementation.

A `storageSpace` `offset` value **MUST** be included.  This is explicitly marked in the below section for clarity.  

*MEMBERS_LIM* refers to the total max quantity of struct members permitted within a single extendible struct.  
*ENTRIES_LIM* refers to the max amount of entries in a storage space, and serves as the upper limit for *push* and *pushMany*.  

`A`, `B`, `C` hash offset structure not only allows CDS to functionally guarantee safety from collisions, but also aid in debugging by 
allowing maintainers to instantly track the high-level objective of complex storage operations.

**Metadata Root:**  
`offset := shl(176, mul(storageSpaces, MEMBERS_LIM))`  
`mstore(0x0, offset)`  
`ROOT_SLOT := keccak256(0x0, 0xA)`  

**Storage Space State Data:**  
`sload(ROOT_SLOT)` → {`members(64), entries(64), stringIndex(64), safeIndex (64)`}  

**Storage Space Member-Specific Data:**  
`sload(add(ROOT_SLOT, add(1, memberIndex)))` → {`bitCount(128), size(64), type(64)`}   
*String*: `sload(add(ROOT_SLOT, add(1, memberIndex)))` → {`stringIndex(128), type(128)`}  

![Storage Metadata](../assets/erc-7844/FirstInitCreateStorageMetadata.svg)

**Live Data:**  
`mstore(0x0, shl(168, add(entryIndex, mul(ENTRIES_LIM, storageSpace))))`  
`INDEXED_DATA_ROOT_IN_STORAGE_SPACE = keccak256(0x0, 0xB)` → {`packed slot`}    
Use `bitCount` and size (in member-specific data) to derive the location of a  
desired struct member in an indexed storage space.  

![Live Data Storage](../assets/erc-7844/LiveDataStorage.svg)

**Storage Space Dynamic Data:**  
`[strindex (32)][entryIndex (32)][storageSpace (32)]`  
```solidity
        mstore(
            0x0,
            or(
                or(shl(224, entryStrindex), shl(192, entryIndex)),
                shl(160, and(storageSpace, 0xFFFFFFFF))
            )
        )
        ENTRY_SLOT := keccak256(0x0, 0xC)
```

**Storage Space Dynamic Data Length:**  

```solidity
	root := sload(ENTRY_SLOT)
	len := shr(224, sload(ENTRY_SLOT))
```  
The length of strings (which functionally double as arrays) is stored in the root slot, with data stored afterwards.  We use this layout because it simplifies storage operations and conversion to the native string type.
![String Layout](../assets/erc-7844/StringLayout.svg)

**entryIndex, memberIndex**:  
*entryIndex* **MUST** refer to a mapped index.  Note that CDS operates with sequential indexing: 0, 1, 2, 3, etc.  
*memberIndex* **MUST** refer to a particular struct member.  

**High-level Solidity equivalent (memberIndex, entryIndex):**

```solidity
	struct Dog
	{
		string furColor;    //memberIndex 0
		string eyeColor;    //memberIndex 1
		uint128 toothCount; //memberIndex 2
		uint128 legsCount;  //memberIndex 3
	}

	mapping(uint256 => Dog) dogs;
	dogs[6 /*entryIndex*/].furColor /*memberIndex 0*/ = 'brown';
```

For example, a *put* invocation **MUST** look like: *put(data, memberIndex, entryIndex, storageSpace)*. 

*stringIndex, safeIndex*:
String index **MUST** be utilized to separate strings in the contract storage space.  Given that strings MUST have a dynamic size, they do not use `bitCount`.  Hence, we MUST fill their `bitCount` with `stringIndex` instead in member data.

However, this raises a problem when implementing extendable structs: *if the last member is a string, we might reference back to its `memberIndex`, tricking the system into believing the `stringIndex` is a `bitCount`.* Hence, we **MUST** leverage `safeIndex`, which records the most recent valid `memberIndex` we can use to derive `bitCount`.  Critically, if `safeIndex` is zero, we are still safe from complications, because a zero `strindex` doubles as a valid `bitCount` in that instance: there are zero preceding bits.

Example Implementation:
```solidity
function insert_new_member(
	uint256 valType,
	uint256 valSize,
	uint256 storageSpace
) external
{
	verify type and size
	retrieve memberData
	
	if(type not string)
	{
		get safeIndex
		assign bitCount := prev bitCount + sizeof previous
		verify size
		get storage page
		verify we will not overflow
		if overflow, push to next page (update bitCount to head of next page)
		pack memberData
		store memberData
		update safeIndex, members in state data for storage space
	}
	if(type is string)
	{
		get stringIndex
		pack with type
		store packed metadata in memberData
		increment stringIndex, members
		store updated state data for storage space
	}

}
```

**Permission Management:**  
Developers **MUST** include a permission management scheme for their CDS model.  They **MAY** utilize the following basic structure:  

| **Permission Holder**      | **ID** | **Significance**      |
| -------------------------- | ------ | --------------------- |
| `User`                     | 1      | View Permissions      |
| `User`                     | 2      | Permission Management |
| `User`                     | 3      | Full Permissions      |
| `Contract`                 | 4      | View Permissions      |
| `Contract`                 | 5      | Permission Management |
| `Contract`                 | 5      | Full Permissions      |


### Interfaces
```solidity
    function init_create(
    uint256[] memory types, 
    uint256[] memory sizes
) external;

    function insert_new_member(
    uint256 valType, 
    uint256 size, 
    uint256 storageSpace
) external;

function push(
	uint256 storageSpace
) external;

function pushMany(
    uint256 amount, 
    uint256 storageSpace
) external;

function put(
    uint256 data, 
    uint256 memberIndex, 
    uint256 entryIndex, 
    uint256 storageSpace
) external;

function put_string(
	string memory data, 
	uint256 memberIndex, 
	uint256 entryIndex, 
	uint256 storageSpace
) external;

function get(
    uint256 memberIndex, 
    uint256 entryIndex, 
    uint256 storageSpace
) external view returns(uint256);

function get_string(
    uint256 memberIndex, 
    uint256 entryIndex, 
    uint256 storageSpace
) external view returns(string memory returnValue);

function set_permissions(
	uint256 level,
	address recipient
) external;

function get_storage_space_state_data(
    uint256 storageSpace
) external view returns(
	uint256 members, 
	uint256 entries,
	uint256 stringIndex,
	uint256 safeIndex
);

function total_members(
    uint256 storageSpace
) external view returns(uint256);

/**
* For string, bitCount->stringIndex, size param is extraneous.
*/
function get_member_data(
	uint256 memberIndex,
	uint256 storageSpace
) external view returns(
	uint256 bitCount, 
	uint256 valSize,
	uint256 valType, 
);

function get_permission_level(
	address target
) external view returns(uint256);

```

### Optional Interface Members
```solidity 
function put_batch(
   uint256[] memory values, 
   uint256[] memory members, 
   uint256 entryIndex, 
   uint256 storageSpace
) external;

function get_batch(
    uint256[] memory members, 
    uint256 entryIndex, 
    uint256 storageSpace
) external view returns(uint256[] memory result);

function get_index_from_address(
	address indexAddress,
	uint256 memberIndex,
	uint256 storageSpace
) external view returns(uint256 entryIndex);

function map_address_to_index(
	address indexAddress,
	uint256 storageSpace,
	uint256 targetIndex
) internal;

function put_with_address(
	address indexAddress,
	uint256 storageSpace,
) external;

function _get_root_slot(
	uint256 storageSpace
) internal view returns(uint256);

```
### Initialization

![Basic Interaction Flow](../assets/erc-7844/BasicInteractionFlow.svg)
![CDS Init, Extension](../assets/erc-7844/CDSInitExpansion.svg)  
The `init_create` function **MUST** handle storage space creation in both an initialization and live extension setting.  The function **MUST** take an array of types and sizes as input, which **MUST** conform to the above specifications, and be equivalent in length when input.  Developers **MUST** include length equivalency validation for `types` and `sizes`.

```solidity
function init_create(
	uint256[] memory types,
	uint256[] memory sizes,
)
{
	/*
		Recommended:
		storageSpaces += 1;
		ROOT_SLOT = _get_root_slot(storageSpaces - 1);
	*/
	for(i in range sizes)
	{
		if(types[i] in [1..5])
		{
			validate size given type
			calculate bitCount for new entry
			pack {bitCount, types, sizes}
			store the packed value in the member data of the storage space
			bitCount := bitCount + size
			increase safeIndex
		}
		if(types[i] is 6)
		{
			create packed value {stringIndex, 6}
			store the packed value in the member data of the storage space
			increment stringIndex
		}
	}
	pack storage space data: {members, entries, stringIndex, safeIndex}
	store storage space data
	storageSpaces += 1
}
```

## Rationale  
Proxy-Delegate and Diamond Storage architectures have long been the industry standard for upgradeable smart contracts, providing critical mechanisms for separating logic from state. These approaches have enabled modular contract upgrades, mitigated contract size limitations, and allowed systems to evolve over time. However, as protocols scale, new challenges emerge—managing storage across multiple contracts, coordinating upgrades, and ensuring compatibility without introducing technical debt or unnecessary redeployments.

CDS builds upon these established patterns by introducing a dedicated, structured storage layer that eliminates many of the complexities inherent in Proxy-Delegate and Diamond architectures. In traditional models, storage modifications require careful slot management, pre-planning reserved fields, or governance-heavy migrations to maintain compatibility. These constraints impose operational overhead and increase the risk of misalignment between logic and storage. CDS removes these limitations by enabling in-place schema evolution, ensuring that storage structures expand deterministically without slot corruption, ABI misalignment, or redundant redeployments.

One of the key improvements CDS introduces is standardized storage access across contracts. Whereas Proxy-Delegate and Diamond models require each contract to define its own storage mappings, CDS provides a shared, structured interface that multiple contracts can access consistently. This reduces cross-contract storage fragmentation, simplifies state synchronization, and eliminates the inefficiencies of multi-hop storage dependencies and redundant mappings.

Furthermore, CDS is designed with long-term system maintainability in mind. As protocols expand, managing state across interdependent contracts becomes increasingly complex. CDS mitigates these risks by externalizing structured storage into a permissioned, extendable layer, ensuring that high-throughput contract interactions remain efficient even as ecosystems grow in scale and complexity.

Proxy-Delegate and Diamond architectures remain valuable for many upgradeable contract designs, offering modularity and logic flexibility. However, for protocols requiring sustainable long-term upgradeability, efficient cross-contract storage, and deterministic schema evolution, CDS provides a more scalable and future-proof alternative. By eliminating migration risks and reducing upgrade complexity, CDS ensures storage integrity, seamless interoperability, and efficient state management—empowering developers to focus on core logic rather than maintenance overhead.

## Backwards Compatibility  

This ERC introduces a new design pattern and does not interfere with existing Solidity implementations. CDS *does* *not* implicitly interfere with common libraries such as those provided by OpenZeppelin, but is not supported explicitly. Library-imposed global data within CDS-linked contracts can be a burden if it is not refactored to link to your CDS layer.

## **Test Cases**

### **1. Core Functionality**

- **Initialization**
    - Input: `types = [1, 3, 6], sizes = [32, 8, 128]`.
    	- Expected: Storage space initialized with 3 members.
- **Insert New Members**
    - Input: `insert_new_member(1, 128, storageSpace = 0)`.
    	- Expected: New `uint128` member added with correct `bitCount`.
- **Data Storage and Retrieval**
    - Input: `put(42, memberIndex = 0, entryIndex = 0, storageSpace = 0)` → `get(0, 0, 0)`.
    	- Expected: `42`.

### **2. Edge Cases**

- **String Handling**
    - Input: Insert five strings consecutively.
    	- Expected: No collisions; strings retrieved accurately.
    
    - Input: insert two dynamic strings, then one uint256
		- Expected: uint256 is properly configured with:
				`bitCount == 0` 
			because: 
				`safeIndex == 0` maps to the dynamic string with index `0`.  This zero value fills both decoded `{type, size}` slots in the standard type construction logic.  Hence, we begin with a valid `bitCount` of `0`.
		    
- **Entry Creation**
    - Input: Add `10,000` entries to a storage space with `pushMany`.
    	- Expected: System can store to any of these entry indices.
    
- **Invalid Input**
    - Input: `put(42, memberIndex = 1, storageSpace = 0)`.
    	- Expected: Reverts with error.
    
	* Input: `put("42", memberIndex = 1, entryIndex = 0, storageSpace = 0)`.
    	- Expected: Reverts with error.
    
	- Input: `put_string(42, memberIndex = 1, entryIndex = 0, storageSpace = 0)`.
    	- Expected: Reverts with error.

### Gas Benchmarks

* This section assumes that storage operations interact with pre-populated slots.  
* These values are derived from the optimized HoneyBadger model and serve as good targets for efficiency.  
* Displayed values reference *execution* cost.  

	`init_create([1], [256]):` 93,860 gas  
	`init_create([1,1,1], [8,256,256]):` 140,024 gas  
	`insert_new_member:` 40,653 gas  
	`push:` 10,316 gas  
	`put:` 15,543 gas  
	`put_batch([20, 20], [0, 1], 0, 0):` 22,895 gas  
	`get`: 9374 gas  

## Reference Implementation

Refer to [CDS Minimal Example](../assets/erc-7844/CDSMinimal.sol)

### Notable Downsides and Mitigating Solutions

While CDS represents a definite step of progress towards efficient, unfettered scalability, 
it does bring about challenges beyond the relative difficulty of implementing a working model.

### Address Indexing
**Impact:** The standard CDS model is locked to uint indexing, which is restrictive for numerous usecases.

**Solution:** The core model does not natively support address indexing (i.e.; *mapping(address => uint256)*), as this inclusion would excessively bloat implementation overhead if included in the baseline model. 

However, CDS can be implemented with a *mapping(uint256 => mapping(address => uint256))*, 
-- representing storageSpace -> address index -> entryIndex -- and an additional mapping 
from *uint256* to *bool* that flags storage spaces as address-indexed.  Contract calls to 
address-indexed storage spaces should first resolve the entryIndex by invoking *get_index_from_address* before interacting with the system as normal.  

To ensure that address-indexed storage spaces are properly populated with addresses, 
it is recommended to leverage the *put_with_address* function when populating 
the storage space. 

While this approach is cumbersome, it effectively introduces address indexing without 
requiring significant additional effort.  

To support other non-uint-indexing capabilities, it is recommended to leverage the same pattern as is used for address indexing. 

### Rigidity of CDS Itself
**Impact:** Standard CDS models are unable to accommodate logical extensions, which can restrict autonomy in a production setting.

**Solution:** As the above example demonstrates, there are cases where extending the baseline CDS implementation is desirable.  Accomplishing this simply requires leveraging the proxy-delegate model for your CDS implementation.

### Non-Descriptive Syntax
**Impact:** One of the most common complaints about CDS is that it effectively masks operations behind a non-descriptive syntax (i.e.; *put(1200, 0, 0, 2)).*  

**Solution:** The best way to mitigate this issue is to pair the non-descriptive syntax with descriptive comments and liberal use of Enums.  

By defining an Enum to name the members of an extendible struct, and another to encode storage spaces, we can significantly enhance the readability of our CDS syntax with little effort.

**Without Enums:** *put(123, 0,0, 1);*  
**With Enums:** *put(123, Globals.TotalBottles, 0, StorageSpaces.Globals);*  


### Storage Space Permanence
**Impact:** Mistakes in defining storage space members are permanent.

**Solution:** While this seems like a significant problem at face-value, it is actually relatively benign because *CDS is leveraged by linked contracts, not users.*  Hence, mistaken struct members can simply be denoted as "inert" within the master docstring and removed from linked contracts.  

## Security Considerations

While a CDS implementation imposes considerable overhead in terms of up-front effort, comprehensively addressing security risks is relatively straightforward.

### Hash Structure and Masking 
Validate your hash structure and masks stringently.  It is recommended to manually verify each operation at least once, using an external document to track verified operations.  Fuzzing key operations is also highly-advised.  While the widespread utilization of complex assembly operations seems daunting, this process is more tedious than it is complicated.  The key is to be diligent - it will either work, or it won't.  If it doesn't work, unit tests and fuzzing will demonstrate that.  While the system is complex under the hood, errors are easy to identify in practice, and they generally arise from improper assembly-level operations.

### Access Control 
It is highly recommended to fully lock the system with a permission management scheme.  The most basic example would be to use a `mapping(address => boolean) hasPerms` with a related modifier.  Users who lack authorization should never have direct access to the system, including view functions.  In the case of views, we prevent access because there is no need for non-users to have insight into your storage space scheme.  It is recommended to use an abstraction layer via an additional contract to ensure that this information is abstracted away, and that users can't pry into data they shouldn't have access to.

### Types and Sizes 
Types and sizes also represent an important vulnerability point.  It is crucial to verify that types are within bounds, and to thoroughly verify that entries conform to expected size(s).  It is best practice to revert when encountering an incorrect size (i.e.; boolean, size 16) rather than correcting it in-place.

## Copyright

Copyright and related rights waived via [CC0](../LICENSE.md).
